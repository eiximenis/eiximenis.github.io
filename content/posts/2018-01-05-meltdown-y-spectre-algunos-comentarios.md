---
title: Meltdown y Spectreâ€¦ algunos comentarios

author: eiximenis

date: 2018-01-05T12:27:46+00:00
geeks_url: /?p=1978
geeks_ms_views:
  - 1243
categories:
  - otros

---
dBueno, todo el mundo estÃ¡ hablando sobre Meltdown y Spectre los dos ataques que aprovechan fallos de los microprocesadores &#8220;modernos&#8221; Intel (el primero) y de cualquier fabricante (el segundo). Como digo muchos medios ya han hablado de ambos ataques, en muchos casos con titulares grandilocuentes y sensacionalistas y contando apenas nada.
  
En este post voy a intentar explicar como funcionan ambos ataques, aunque me centrarÃ© en Meltdown por ser el mÃ¡s fÃ¡cil de explicar, entender y aplicar. Spectre se basa en los mismos conceptos, pero es un ataque bastante mÃ¡s complejo.
  
Voy a intentar explicarlo de un modo &#8220;entendible&#8221;, pero obviamente eso requiere ciertos conocimientos tÃ©cnicos, pero bueno... ese es un blog de desarrollo, asÃ­ que seguramente los tienes ğŸ˜‰
  
<!--more-->


  
**La causa: optimizaciones**
  
Empecemos por la causa que abre la puerta a esos dos ataques: lasÂ _optimizaciones_. Pero no optimizaciones del compilador, si no del propio micro-procesador. En este caso parece ser que la raÃ­z de Meltdown es elÂ _out of order execution_ y la de Spectre esÂ _branch prediction_. Ambas optimizaciones son un tipo concreto de otra mÃ¡s general conocida comoÂ _speculative execution_.
  
Todos tenemos en mente la idea de que un microprocesador va ejecutando las instrucciones (en cÃ³digo mÃ¡quina) una tras una. Eso serÃ­a lo normal, pero tiene un problema: el **microprocesador es condenadamente rÃ¡pido en comparaciÃ³n con todo lo demÃ¡s**. Si dada una instrucciÃ³n para leer un dato de la memoria RAM, el microprocesador debe esperarse a que el dato llegue al registro, estarÃ­a la mayor parte de su tiempo parado. La RAM es rÃ¡pida pero el procesador lo es mucho mÃ¡s.
  
**Meltdown y Spectre**
  
Por eso hay esas opimizciones y una es la deÂ **out of order execution**. BÃ¡sicamente esto quiere decir que dado una secuencia de instrucciones el microprocesador ejecuta cada una de ellas tan rÃ¡pido puede,Â **es decir una vez sus operandos estÃ¡n listos**. Por supuesto si hay interdependencias no puede hacer esto, pero si no las hay es posible que el procesador ejecute la primera instrucciÃ³n (que accede a RAM) y mientras no llegue el dato ejecute la siguiente si es que esta siguiente accede a datos de los registros.
  
Vamos a ver un ejemplo, pero no en ensamblador si no en &#8220;alto nivel&#8221; (asumimos que cada lÃ­nea es una instrucciÃ³n del procesador) para entenderlo mejor:

<pre class="EnlighterJSRAW" data-enlighter-language="null">throw new Exeception();
var a = b[1000];</pre>

Â¿Es obvio que la segunda lÃ­nea nunca se va a ejecutar verdad? Es tan obvio que es falso. El procesador empieza a ejecutar la primera instrucciÃ³n pero como tarda porque estÃ¡ a la espera de un recurso, mientras tanto ejecuta la segundaÂ **y accede a la posiciÃ³n 1000 del array**. Posteriormente la primera instrucciÃ³n termina y se lanza la excepciÃ³n,Â **en este momento el procesador echa todo lo demÃ¡s para atrÃ¡s y queda exactamente en el MISMO estado en el que estarÃ­a si solo hubiera ejecutado la primera instrucciÃ³n.**
  
Desde un punto de vista lÃ³gico todo es correcto:Â **no queda rastro alguno de que se haya accedido a la posiciÃ³n b[1000]**. Aunque se haya accedido a ella, el procesador echa toda la ejecuciÃ³n para atrÃ¡s. Si este valor estaba en un registro, el registro vuelve a su estado anterior. EsÂ **como hacer un rollback en una base de datos**.
  
La otra optimizaciÃ³n es la deÂ _branch prediction_ que se basa en cada vez que el procesador llega a una instrucciÃ³n de bifurcaciÃ³n,Â **empieza a ejecutar una de las dos ramasÂ _antes_ de evaluar la comparaciÃ³n**. De este modo, si ha acertado, todo eso que ha ganado. Y si ha fallado, pues bueno, el procesador hace elÂ _rollback_ y empieza a ejecutar la otra rama. Los procesadores actuales usan heurÃ­sticas y son muy buenos en acertar que rama es la que se ejecutarÃ¡ y eso permite ahorrar tiempo.
  
Como digo, es como hacer un rollback de base de datos... excepto que sÃ­ que queda un rastro. Y este es el rastro que explotanÂ _Meltdown y Spectre_. Y tiene que ver con otra optimizaciÃ³n: la cache.
  
Y es queÂ **cuando el procesador accede a la RAM usa unaÂ _cache_ (interna del procesador y mucho mÃ¡s rÃ¡pida que la RAM)Â y si el dato no estÃ¡ en laÂ _cache_ lo recupera de la RAM y lo mete en laÂ _cache_ para posibles posteriores usos**. Hasta aquÃ­ todo correcto: para eso tenemos lasÂ _cache_. PeroÂ **existe un &#8220;problemilla&#8221;: cuando el procesador hace el &#8220;rollback&#8221; no echa para atrÃ¡s los datos de laÂ _cache_.**
  
Bueno &#8220;problemilla&#8221; lo he puesto entre comillas, porque esaÂ _cache_ es interna. No hay manera de acceder a ella. No hay instrucciÃ³n en ensamblador para obtener un dato de laÂ _cache_, todo eso lo hace el procesador entre bambalinas. AsÃ­ que no limpiar la cache no deberÃ­a suponer ningÃºn problema. Por eso precisamenteÂ **y de forma consciente se optÃ³ por no hacerlo**. Revertir el estado de laÂ _cache_ serÃ­a muy lento. Tanto que echarÃ­a al traste la ganancia de tiempo deÂ _out of order execution_ en el caso de que tuviÃ©ramos que ir para atrÃ¡s. No compensa y total nadie puede acceder a laÂ _cache_ para saber que hay en ella.
  
**Y es cierto: nadie puede leer de laÂ _cache_**.
  
Pero sÃ­ que podemos hacer otra cosa mucho mÃ¡s perversa e inteligente:Â **medir cuanto tiempo tardamos en leer un dato de la memoria**. Si tardamos &#8220;poco&#8221; tiempo, es que este dato estaba en laÂ _cache_ y si tardamos mÃ¡s tiempo es que no estaba. Es decir,Â **no podemos saber que hay en laÂ _cache_, pero midiendo tiempos podemos saber si un dato en concreto estÃ¡ en ella**. Y este es el vector de ataque.
  
Es decir, **no nos basaremos en leer datos de laÂ _cache_ (eso serÃ­a un error de seguridad gravÃ­simo), se basa en averiguar si un dato estÃ¡ o no en base al tiempo que tardamos en acceder a Ã©l**. Vale... pero de nuevo: Â¿por quÃ© esto nos permite acceder a memoria no autorizada (la del kernel u otro proceso)?. **Si yo intento leer un dato prohibido para ver si estÃ¡ o no en la _cache_, nunca lo sabrÃ© porque recibirÃ© siempre una excepciÃ³n**. Es decirÂ _a priori_, otra vez, parece que no hay posibilidad de ataque. Pero, como siempre, la hay.
  
A grandes rasgos Meltdown (y una de las variantes de Spectre) se basan en algo similar (salvando las distancias, claro) a hacer lo siguiente:

  1. Crear dos arrays del mismo tamaÃ±o
  2. Comprobar que el Ã­ndice pasado estÃ¡ dentro del array1
  3. Si es OK leer el array1 a este Ã­ndice
  4. A partir de un bit del resultado de 3Â **calcular otro Ã­ndice del segundo array**
  5. Comprobar que este segundo Ã­ndice estÃ¡ dentro del array2
  6. Acceder al array2 con este Ã­ndice

Â¿Os parece poco malicioso, verdad? Â¡Es que lo es! Pero este cÃ³digo es la base de Meltdown. La pregunta Ã©sÂ **Â¿quÃ© ocurre con este cÃ³digo cuando accedemos a un Ã­ndice invÃ¡lido al array1?** Pues que el cÃ³digo termina en el paso 2. El paso 3, 4, 5 y 6 no se ejecutan nunca.
  
Vale, pero hemos visto que hayÂ _out of order execution_ lo que significa que estos pasos sÃ­ que pueden ejecutarse y ya luego, cuando se demuestre que el paso 2 termina el procesador harÃ¡ su &#8220;rollback&#8221;. Ahora, y aquÃ­ estÃ¡ la sutileza, observa que hemos leÃ­do de la memoria una posiciÃ³n del array2Â **y lo hemos hecho en base a un bit del valor en una posiciÃ³n del array1**, a la que no tenÃ­amos acceso. Algo como, si el primer bit es 1 accedes a array2[1] y si es 0 accedes a array2[1]. Esto es lo que hace el punto 6.
  
Â¿Y eso quÃ© significa? Pues queÂ **o bien el valor de array2[1] o el de array2[0] estÃ¡n ahora en laÂ _cache_.**Â Â¿Por lo tanto quÃ© debes hacer? Muy sencillo: acceder a array2[0] y hay dos posibilidades:

  * La lectura tarda &#8220;mucho&#8221;, porque array2[0] no estaba en la cache,Â _ergo_ eso significa que el primer bit del valor de array1 al que no tienes acceso era un 1.
  * La lectura tarda &#8220;poco&#8221;, porque array2[0] estaba en la cache (recuerda que no se limpia tras el &#8220;rollback&#8221; del procesador&#8221;. Eso significa que el valor del primer bit de array1 al que no tienes acceso era un 0

Ahora solo tienes que repetir este proceso N veces y usar cada vez un bit distinto del valor &#8220;prohibido&#8221; de array1 para obtener los N bits de array1.
  
Es decirÂ **obtienes todos los bits (uno a uno) de una direcciÃ³n de memoria a la que NO tienes acceso, mediante la mediciÃ³n de tiempos de la lectura de otra direcciÃ³n vÃ¡lida (a la que SI tienes acceso), que estÃ¡ o no en la cache del procesador, en funciÃ³n del valor de uno de los bits de la primera direcciÃ³n**.
  
Ahora sustituye &#8220;array1&#8221; por &#8220;puntero a la direcciÃ³n de memoria delÂ _kernel_&#8221; y listos. En este caso el paso 2 que tenÃ­amos lanza una excepciÃ³n (no puedes acceder a memoria del kernel (anillo 0) desde cÃ³digo de usuario (anillo 3)). Pero claro, recuerda que &#8220;gracias a&#8221; la ejecuciÃ³n especulativa el resto de pasos se han ejecutado (y al haber la excepciÃ³n se hace el &#8220;rollback&#8221;). AsÃ­ pues puedes &#8220;inferir&#8221; toda la memoria delÂ _kernel_. No la &#8220;lees&#8221; directamente, lo que haces es &#8220;deducirla&#8221; bit a bit.Â **Pues eso es, a grandes rasgos, Meltdown y Spectre** (al menos una de sus variantes).
  
Por lo tanto son varias las causas que dan lugar al ataque:

  1. _Speculative execution_: El procesador ejecuta instrucciones de forma especulativa, fuera de orden o en otra rama de decisiÃ³n.
  2. El uso deÂ _cache_
  3. Que en el rollback de laÂ _speculative execution_ no se limpia laÂ _cache_

Los tres puntos tienen una cosa en comÃºn:Â **se prima la velocidad a la seguridad**.
  
El hecho de que Meltdown parece (no estÃ¡ confirmado) que afecta solo a Intel es porque los procesadores Intel permiten que una referencia especulativa en anillo 3 acceda a memoria del anillo 0 (en nuestro caso permiten ejecutar el punto 3 de forma especulativa si asumimos que array1 es la memoria del kernel). Parece ser que AMD no permite eso, de forma que al no ejecutarse nunca el punto 3, no tendrÃ­amos nada en laÂ _cache_ con lo que nada podrÃ­amos inferir. Precisamente por eso Spectre les afecta, porque en Spectre &#8220;array1&#8221; no es el kernel si no memoria virtual localizada en un espacio de direcciones de otro proceso, pero en el mismo anillo 3. Y sÃ­ que se permite una lectura de una referencia especulativa a una direcciÃ³n del anillo 3 en cÃ³digo de anillo 3 (obviamente, si no, no permitirÃ­as ninguna).
  
Â¿Es eso unÂ _bug_? Pues bueno, depende de como se mire. Â¿Es un problema? Eso sÃ­. Sin duda.
  
**El parche a Meltdown**
  
Para Spectre no hay parche a la vista ni lo habrÃ¡ creo yo. SÃ­ que saldran acciones puntuales, pero veremos. Para Meltdown sÃ­ que hay un parche y es literalmente: quitar el kernel de la memoria virtual de los procesos en anilla 3 (lo que se conoce como KAISER).
  
Ahora mismo la memoria del ordenador se divide en dos partes: la de usuario que usan los programas y la del Kernel. Generalmente se asigna una porciÃ³n de memoria virtual para cada proceso (supongamos 2GB) y el resto (otros 2GB si estamos en 32 bits) para el Kernel.Â **El Kernel estÃ¡ fÃ­sicamente en un solo lugar de la memoria y se mapea a cada memoria virtual de cada proceso en la misma direcciÃ³n**. AsÃ­ si yo tengo un puntero y sÃ© que el Kernel empieza en la direcciÃ³n virtual X, puedo intentar leer de ella. Eso me generarÃ¡ una excepciÃ³n si lo hago &#8220;a saco&#8221; ya que estoy en anillo 3. Si lo hago &#8220;correctamente&#8221;, es decir llamando a mÃ©todos del Kernel, en algÃºn momento el cÃ³digo salta a anillo 0 y entonces el Kernel puede leer su memoria. AsÃ­ es a grandes rasgos como funciona.
  
Â¿Y el parche que hace? Pues bÃ¡sicamenteÂ **quita el Kernel de la memoria virtual del proceso**. La parte reservada al Kernel estarÃ¡ vacÃ­a (o casi, es imposible vaciarla toda). Por lo tanto ahora cuando hagamos una llamada al Kernel y pasemos al anillo 0, el Kernel obtendrÃ¡ su propia memoria virtual y podrÃ¡, por supuesto, acceder a ella. KAISER no es nada maloÂ _per se_. De nuevo la pregunta es Â¿por quÃ© tenÃ­amos la memoria del Kernel mapeada en la memoria virtual de cada proceso? Y la respuesta vuelve a ser: rendimiento.
  
Mapear una direcciÃ³n virtual a una fÃ­sica es un proceso &#8220;lento&#8221; por lo que para acelerarlo existe... sÃ­, lo has acertado: otraÂ _cache_. Pero es unaÂ _cache_ pequeÃ±a y una de las formas de hacer que se llene menos es teniendo mapeado el Kernel en la misma direcciÃ³n virtual de cada proceso. De este modo al cambiar de un proceso al Kernel no aÃ±adimos presiÃ³n a esaÂ _cache_. Pero ahora cuando cambiemos de un proceso al Kernel, esaÂ _cache_ ya no es vÃ¡lida, ya que las direcciones virtuales cambian, lo que significa que perdemosÂ _cache hits_. Es esa pÃ©rdida, bÃ¡sicamente, la que genera esa pÃ©rdida de rendimiento que se cifra entre un 1 y un 50%... que depende bÃ¡sicamente de cuantos cambios de Kernel a espacio de usuario tengamos.
  
Y bueno... espero que os haya aclarado algo. Como digo es un resÃºmen un poco basto de lo que es Meltdown y Spectre. Si querÃ©is profundizar mÃ¡s en como funcionan leeros los papers que los describen (disponibles en [Meltdownattack][1]Â pero son un poco &#8220;duros&#8221;, aviso xD).

 [1]: https://meltdownattack.com/