---
title: "De runas y grafemas en Unicode y NET6"
author: eiximenis
description: "Un carÃ¡cter en Unicode es algo complejo de definir. Veamos como estÃ¡ la situaciÃ³n en NET6"
date: 2021-01-31
draft: false
categories:
  - dotnet
tags: ["unicode", "dotnet", "c#"]
---

Hace algÃºn tiempo (varios aÃ±os xD) escribÃ­ un post sobre [encodings en Unicode](https://www.eiximenis.dev/posts/2018-10-01-unicode-y-encodings/) en el que comentaba un poco el lÃ­o de codificaciones que tenemos en Unicode, y que significa UTF-8 o UTF-16. Te lo puedes leer si quieres pero si no aquÃ­ tienes un pequeÃ±o resÃºmen de lo mÃ¡s importante que comentaba y que es necesario para entender de lo que quiero hablarte hoy.

Lo mÃ¡s importante de aquel post eran los siguientes tres puntos:

* El concepto _code point_ en Unicode que es lo que equivaldrÃ­a a "carÃ¡cter". Hay muchos (mÃ¡s de 2 a la 16) _code points_ distintos en Unicode
* El concepto de _code unit_ (valor de 16 bits) que **es propio de UTF-16**. Un _code point_ puede estar formado por varios _code units_.
* En .NET un `System.Char` representa un _code unit_ y no un _code point_. 

El tercer punto es clave ya que significa que:

* Una variable `char` es posible que no se corresponden a ningÃºn carÃ¡cter real (no todos los _code unit_ se corresponen a un _code point_).
* Hay carÃ¡cteres Unicode que no se pueden representar usando un `char` y necesitamos mÃ¡s de uno.

## Runas (aka code points)

El nombre de runa suena muy esotÃ©rico **y no estÃ¡ definido en ningÃºn estÃ¡ndard** pero quedÃ©monos con que una runa es exactamente lo mismo que un _code point_ pero en nomenclatura C# (eso viene de que esa parte de la API de .NET estÃ¡ fuertemente inspirada en su equivalente de Golang y en Golang eligieron dicho nombre).

AsÃ­ una runa es un valor de 32 bits (como podrÃ­a ser un `System.Int32`) que se mapea a un _code point_, es decir a un carÃ¡cter Unicode. Vamos a verlo. Imagina el siguiente cÃ³digo:

```csharp
var s = "A";
Console.WriteLine(s.Length);
```

Â¿CuÃ¡l es el resultado de ese programa? **Supongo que todos habÃ©is dicho 1, ya que la cadena `"A"` tiene un carÃ¡cter**. Efectivamente la salida es 1. Sigamos:

```csharp
var s = "ğŸ˜€";
Console.WriteLine(s.Length);Rune is ğŸ˜€ with value 128512
```

Â¿Y ahora cual es la salida? Uno podrÃ­a pensar que deberÃ­a seguir siendo 1, ya que tenemos un solo carÃ¡cter (recuerda que en Unicode los emojis son carÃ¡cteres como los demÃ¡s). Pero la realidad **es que la salida es 2**. Â¿Y por quÃ© es 2 la salida, si solo hay un carÃ¡cter? Pues muy sencillo: **porque en .NET una cadena no contiene carÃ¡cteres (_code points_) si no que contiene los _code units_ de UTF-16**. El tipo `System.Char` representa un _code unit_, no un _code point_ y para el carÃ¡cter Unicode 'ğŸ˜€' se requieren 2 _code units_ de UTF-16 para codificarlo. **Las cadenas en .NET estÃ¡n en UTF-16 y este hecho se filtra en la API: NO tenemos una API orientada a carÃ¡cteres, tenemos una API orientada a _code units_ de UTF-16**. No te creas que eso es un problema de los emojis solo: muchos carÃ¡cteres de lenguas extrangeras requieren mÃ¡s de un _code unit_ para almacenarlos por lo que necesitamos mÃ¡s de un `System.Char` de .NET.

Para solucionar este problema, en netcore 3 se introdujo la API de runas:

```csharp
var s = "ğŸ˜€";
var runes = s.EnumerateRunes();
foreach (var rune in runes) {
    Console.WriteLine("Rune is {0} with value {1}", rune, rune.Value);
}
```

El mÃ©todo `EnumerateRunes` devuelve un `StringRuneEnumerator` que nos permite iterar sobre las runas de la cadena. Recuerda que una runa es un _code point_ de Unicode, es decir un carÃ¡cter.

La salida de este programa ahora si que nos indica que sÃ³lamente hay una runa. La salida es como sigue:

```
Rune is ğŸ˜€ with value 128512
```

El valor numÃ©rico que nos aparece (128512 o 0x1f600) es el valor del [_code point_ correspondiente de Unicode](https://www.compart.com/en/unicode/U+1F600) y es de 32 bits. Por lo tanto **el cÃ³digo correcto para saber cuantos carÃ¡cteres reales tiene una cadena NO es usar `String.Length` si no usar `String.EnumerateRunes().Count()`**.

Si quisieras repetir este ejercicio pero en lugar de usar el emoticono metido en el fichero, quisieras usar su codificaciÃ³n Unicode, la cosa no es tan sencilla:

```csharp
var s = "\u1f600";
Console.WriteLine(s);
```

Este cÃ³digo **NO imprime el emoticono** si no que en su lugar imprime `á½ 0`. Â¿QuÃ© ocurre aquÃ­? Pues sencillamente que la notaciÃ³n `\u` nos permite indicar el cÃ³digo Unicode, pero el cÃ³digo Unicode Â¿de quÃ©? No de un _code point_ si no de un _code unit_ de UTF-16 (es decir de un `System.Char`). Por lo tanto despuÃ©s de `\u` siempre van 4 dÃ­gitos hexadecimales (de `0000` a `ffff`) que nos cubren los 16 bits possibles. Por lo que la cadena `"\u1f600"` se toma como una cadena con dos _code units_, el primero con [cÃ³digo Unicode `1f60`](https://www.compart.com/en/unicode/U+1F60) y el segundo es el carÃ¡cter `0`. Si quieres construir el emoji **debes saber como se codifica en UTF-16**:

```csharp
var s = "\ud83d\ude00" 
Console.WriteLine(s);
```

Este cÃ³digo si que imprime el emoticono por pantalla ya que `s` ya que el emoticono ğŸ˜€ en UTF-16 se codifica mediante dos _code units_ (`0xd83d` y `0xde00`), y como un `System.Char` de .NET equivale a un _code unit_ de UTF-16 y un `System.String` es una colecciÃ³n de `System.Char` pues nos toca poner la codificaciÃ³n UTF-16 tal cual. Obviamente da igual si usamos los dos `System.Char` explÃ­citos en la cadena o el emoji directo, el cÃ³digo que detecta las runas funciona igual (ya que realmente ambas cadenas son la misma). AsÃ­ el siguiente cÃ³digo imprime `True`, ya que la condiciÃ³n es cierta:

```csharp
Console.WriteLine("\ud83d\ude00" == "ğŸ˜€");
```

Resumiendo: la API de Runas de C# nos permite obtener los carÃ¡cteres Unicode (_code points_) de la cadena, en lugar de los _code units_ de UTF-16. La realidad es que aquÃ­ se nota que la API de cadenas de .NET tiene sus aÃ±itos (recuerda que en nada .NET cumple 20 aÃ±os xD) ya que, estoy seguro, si se diseÃ±ase ahora desde 0, el valor de `System.Char` se corresponderÃ­a a un _code point_ de Unicode y en todo caso tendrÃ­amos mÃ©todos para obtener una codificaciÃ³n UTF-16 (o UTF-8 o lo que sea) de un `System.Char`.

Igual te preguntas cuando deberÃ­as usar runas y no `System.Char` al trabajar con cadenas. La realidad es que deberÃ­as hacerlo siempre que quieras soportar cualquier posible carÃ¡cter Unicode. Usando `char` entras en riesgo si el carÃ¡cter cae fuera de cierto rango (el que llamamos rango BMP). Por ejemplo, el siguiente cÃ³digo falla miserablemente al contar las letras de la cadena `s`:

```csharp
var s = "ğ“ğ“˜ğ“»ğ“˜ğ“»ğ“Ÿ ğ’»ğ“Ÿ";
var letters = s.Where(c => char.IsLetter(c)).Count();
```

El valor de `letters` es 0. Por otro lado si usamos la API de runas todo funciona correctamente:

```csharp
var s = "ğ“ğ“˜ğ“»ğ“˜ğ“»ğ“Ÿ ğ’»ğ“Ÿ";
var letters = s.EnumerateRunes().Where(r => Rune.IsLetter(r)).Count();
```

Ahora sÃ­ que `letters` tiene el valor correcto (`8`). La clase `System.Text.Rune` tiene muchos de los mÃ©todos estÃ¡ticos que hay en `System.Char` incluyendo `ToUpper` o `ToLower` por ejemplo.

## Grafemas

Vale, ya tenemos claro que si una cadena tiene 3 runas, es que el usuario verÃ¡ 3 carÃ¡cteres en pantalla Â¿no? **Pues no**. Bienvenido al sÃ©ptimo cÃ­rculo infernal de Unicode: los grafemas.

Un grafema (el nombre tÃ©cnico es `grapheme cluster`) es el equivalente de carÃ¡cteres percibidos en pantalla por el usuario. O sea, si una cadena contiene 2 grafemas el usuario verÃ¡ dos carÃ¡cteres en pantalla. AsÃ­ que poniÃ©ndolo todo junto:

* Una `System.String` puede contener varios `code units` de UTF-16. 
  * Cada `code unit` se representa mediante un `System.Char`.
* Todos esos _code units_ son la representaciÃ³n en UTF-16 de varios _code points_ de Unicode.
  * Cada _code point_ se representa mediante un `System.Text.Rune`.
* Todos esos _code points_ de Unicode son la representaciÃ³n de varios grafemas
  * Por cada grafema el usuario percibirÃ¡ un carÃ¡cter

Vamos a ver un ejemplo de grafema. Por ejemplo el carÃ¡cter "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§". Esta adorable famÃ­lia de dos madres y dos niÃ±as **no es un _code point_** de Unicode. No hay ningÃºn carÃ¡cter Unicode que represente a esta famÃ­lia. En su lugar **existe una combinaciÃ³n de _code points_ que forman un grafema**. Concretamente en este caso **hay 7 _code points_ que se combinan para formar ese grafema**. Los podemos ver uno a uno usando la API de runas de C#:

```csharp
var s = "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§";
var runes = s.EnumerateRunes();
foreach (var rune in runes) {
    Console.WriteLine("Rune is {0} with value {1}", rune, rune.Value);
}
```

La salida de ese programa es tal y como se muestra a combinaciÃ³n:

```
Rune is ğŸ‘© with value 128105
Rune is â€ with value 8205
Rune is ğŸ‘© with value 128105
Rune is â€ with value 8205
Rune is ğŸ‘§ with value 128103
Rune is â€ with value 8205
Rune is ğŸ‘§ with value 128103
```

El _code point_ 8205 es un _code point_ "especial", se llama ZWJ (Zero Width Joiner) y se usa, precisamente, en este tipo de combinaciones: para combinar varios _code points_ y formar un grafema. Â¡Ojo! Que el 8205 no es el Ãºnico _code point_ especial, hay muchos mÃ¡s que se usan en otros grafemas. El estÃ¡ndard Unicode pues, no solo define las tablas de carÃ¡cteres (_code points_) y como se codifican (UTF-16, UTF-8, etc) si no que tambiÃ©n define posibles combinaciones de _code points_ para formar distintos grafemas. De hecho, puedes ver que ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§ estÃ¡ formado por varios carÃ¡cteres si, usando Visual Studio Code, te situas justo despuÃ©s del carÃ¡cter y empiezas a borrar:

![Imagen animada donde se va pulsando la tecla de borrar y el grafema va cambiando](/images/posts/2022-02-02-vscode-delete-grafema.gif)

Cada vez que borro, se elimina un _code point_ por lo que el grafema es cada vez distinto, de ahÃ­ que el emoji vaya cambiando cada vez borramos.

Igual te preguntas si es posible en C# saber cuantos grafemas tiene una cadena. Pues la realidad es que sÃ­. **Podemos iterar sobre los grafemas de una cadena**:

```csharp
var s = "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§";
var graphemes = StringInfo.GetTextElementEnumerator(s);
var count = 0;
while (graphemes.MoveNext()) {
    count++;
}
Console.WriteLine("We have {0} graphemes", count);
```

Este cÃ³digo imprime `We have 1 graphemes` en pantalla, indicando que efectivamente la cadena "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§" contiene un solo grafema. TambiÃ©n podemos obtener cada uno de los grafemas:

```csharp
while (graphemes.MoveNext()) {
    var grapheme = graphemes.Current;   
}
```

Ahora, aquÃ­ tenemos un pequeÃ±o problema y es que la variable `grapheme` es de tipo `object?`, ya que no hay un tipo especÃ­fico para representar un grafema. De hecho el objeto devuelto por `Current` es de tipo `System.String`, o sea que podemos usar el siguiente cÃ³digo:

```csharp
var grapheme = (string)graphemes.Current;
```

Por supuesto, puedes usar `as` o incluso usar `graphemes.Current?.ToString()`.

Â¿Y como es que para representar un grafema terminamos con una cadena? Eso es porque, al menos en la versiÃ³n actual de la API (NET6), con los grafemas poco podemos hacer: imprimirlos por pantalla, contarlos y por supuesto (dado que son cadenas) saber sus runas:

```csharp
var s = "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§";
var graphemes = StringInfo.GetTextElementEnumerator(s);
var count = 0;
while (graphemes.MoveNext()) {
    count ++;
    Console.WriteLine($"Grapheme {count}:");
    var grapheme = (string)graphemes.Current;   
    var runes = grapheme.EnumerateRunes();
    foreach (var rune in runes) {
        Console.WriteLine($"Rune is {rune} with code {rune.Value}");
    }
}
Console.WriteLine("We have {0} graphemes", count);
```

La salida de este cÃ³digo es tal y como sigue:

```
Grapheme 1:
Rune is ğŸ‘© with code 128105
Rune is â€ with code 8205
Rune is ğŸ‘© with code 128105
Rune is â€ with code 8205
Rune is ğŸ‘§ with code 128103
Rune is â€ with code 8205
Rune is ğŸ‘§ with code 128103
We have 1 graphemes
```

Por supuesto, un grafema, dado que es una cadena lo podemos imprimir tal cual por consola:

```csharp
var s = "ğŸ‘©â€ğŸ‘©â€ğŸ‘§â€ğŸ‘§";
var graphemes = StringInfo.GetTextElementEnumerator(s);
while (graphemes.MoveNext()) {
    Console.WriteLine("Grapheme:" + graphemes.Current);
}
```

La salida de este cÃ³digo **deberÃ­a ser** la siguiente:

```
Grapheme:ğŸ‘©â€ğŸ‘©â€ğŸ‘§
```

Pero **la realidad es que la salida puede ser cualquier cosa** ya que el soporte de grafemas en terminales estÃ¡ un poco verde. Es decir, es posible que en tu terminal no lo veas bien. Pero la culpa no es de .NET, es del terminal que no gestiona la visualizaciÃ³n de la combinaciÃ³n de _code units_ como un grafema.

Algunas muestras. Muestro una captura de pantalla de la salida del programa junto con el contenido del fichero `Program.cs`. Empecemos por Windows Terminal en su versiÃ³n 1.11.3471.0:

![Salida en WT donde el grafema se ve bien pero con espacios alrededor](/images/posts/2022-02-02-wt.png)

En esta segunda imagen se muestra como se ve en el terminal integrado de VSCode:

![Salida en el terminal de vscode donde el grafema se muestra como sus runas individuales](/images/posts/2022-02-02-vscode.png)

Y en esta tercera como se ve en el terminal por defecto de Ubuntu 21.10:

![Salida en el terminal de Ubuntu](/images/posts/2022-02-02-ubuntu.png)

Como puedes ver, cada terminal lo gestiona distinto. Visual Studio Code es curioso porque en el editor el grafema se ve perfecto, pero en el terminal no.

En resumen, en este post hemos visto las diferencias entre un `System.Char` de .NET, un carÃ¡cter Unicode y un grafema. Espero que este post te haya podido aclarar un poco las ideas y de paso hacerte ver que el soporte que tenemos en .NET para tratar con Unicode es ahora mismo muy bueno.